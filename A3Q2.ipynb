{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2: K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset and process the data\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "# Combining dataset with labels\n",
    "train = np.column_stack((train_X.reshape(-1, 28*28), train_y))\n",
    "test = np.column_stack((test_X.reshape(-1, 28*28), test_y))\n",
    "\n",
    "# Randomly trimming dataset for better performance\n",
    "np.random.shuffle(train)\n",
    "train_y = np.array(train[:100][:, -1])\n",
    "train = np.array(train[:100][:, :-1].tolist())\n",
    "\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 784), (100,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scikit-learn K-Means (for comparison)\n",
    "kmeans = KMeans(n_clusters=10, init='random', max_iter=10, random_state=0, n_init='auto')\n",
    "kmeans.fit(train[0:785])\n",
    "labels = kmeans.labels_\n",
    "centers = kmeans.cluster_centers_\n",
    "centers.shape, labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Training K-Means Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training K-Means classifier\n",
    "def K_Means_Classifier(data, n_clusters, max_iter):\n",
    "\n",
    "    # Initializing the clusters evenly\n",
    "    # centers = data[[j * int(np.floor(data.shape[0] / n_clusters)) for j in range(n_clusters)]]\n",
    "    \n",
    "    # Random initialization\n",
    "    centers = data[np.random.choice(data.shape[0], size=n_clusters, replace=False)]\n",
    "\n",
    "    # Compute Euclidean distances to each cluster center and return the minimum value's index\n",
    "    def assign_cluster(vector):\n",
    "        distances = []\n",
    "        for cluster in range(n_clusters):\n",
    "            distances.append(sum([(vector[i] - centers[cluster][i])**2 for i in vector]))\n",
    "        return np.argmin(np.array(distances))\n",
    "\n",
    "    labels = np.array([assign_cluster(i) for i in data])\n",
    "\n",
    "    # Re-assign clusters\n",
    "    for iteration in range(max_iter):\n",
    "        centers = np.array([np.mean(np.array(data[np.where(labels == cluster)]), axis=0) for cluster in range(n_clusters)])\n",
    "\n",
    "        new_labels = np.array([assign_cluster(i) for i in data])\n",
    "\n",
    "        # Check for convergence by comparing labels with previous iteration\n",
    "        if np.array_equal(labels, new_labels):\n",
    "            print(\"Convergence for k =\", n_clusters, \" at iteration #\", iteration)\n",
    "            return centers, labels\n",
    "        else:\n",
    "            labels = new_labels\n",
    "\n",
    "    return centers, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parts 2, 3: Applying K-Means to MNIST and Accuracy Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for k= 5 :  0.27829573934837093\n",
      "Accuracy for k= 10 :  0.3636510711510712\n",
      "Convergence for k = 20  at iteration # 4\n",
      "Accuracy for k= 20 :  0.4832142857142857\n",
      "Convergence for k = 40  at iteration # 4\n",
      "Accuracy for k= 40 :  0.705\n"
     ]
    }
   ],
   "source": [
    "# Run the algorithm\n",
    "max_iter = 5\n",
    "\n",
    "for k in [5, 10, 20, 40]:\n",
    "    centers, labels = K_Means_Classifier(train, k, max_iter)\n",
    "    accuracies = []\n",
    "    clusters = [train_y[np.where(labels == cluster)] for cluster in range(k)]\n",
    "\n",
    "    # Compute accuracies\n",
    "    for cluster in range(k):\n",
    "        _, counts = np.unique(np.array(clusters[cluster]), return_counts=True)\n",
    "        # Sometimes the algorithm may converge such that all datapoints are forced into a single cluster\n",
    "        # In this case, assume that cluster's accuracy is 0\n",
    "        accuracies.append(0 if counts.shape[0] < 1 else max(counts)/len(clusters[cluster]))\n",
    "\n",
    "    # Output the average accuracy\n",
    "    print(\"Accuracy for k=\", k, \": \", sum(accuracies) / k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster accuracies for K=40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.33333333, 0.66666667, 0.25      , 1.        ,\n",
       "       1.        , 0.25      , 1.        , 1.        , 1.        ,\n",
       "       0.66666667, 0.5       , 1.        , 0.25      , 1.        ,\n",
       "       1.        , 1.        , 1.        , 0.83333333, 0.5       ,\n",
       "       0.66666667, 0.33333333, 0.5       , 0.5       , 1.        ,\n",
       "       0.75      , 1.        , 0.5       , 1.        , 1.        ,\n",
       "       1.        , 0.66666667, 1.        , 0.2       , 1.        ,\n",
       "       0.5       , 0.5       , 0.5       , 0.33333333, 0.5       ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Cluster accuracies for K=40\")\n",
    "np.array(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 4: Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which k value produces the best results?**\n",
    "\n",
    "The higher values of $k$ produce better results according to cluster consistency, so $K=40$ resulted in the highest 'accuracy' at $73%$. This is because cluster consistency is naturally biased toward smaller cluster sizes (ie. larger $K$ values). Mathematically the $N_i$ term will be lower so it is easier to score a higher accuracy. Observe that many of the individual cluster accuracies were 100% in the output above. In this sense, cluster consistency is a misleading accuracy measure. Graphically it would also visibly not lead to good results if done on 2D data; for example 10 clusters on 10 datapoints would result in 1 datapoint per cluster, or 100% consistency but this defeats the purpose of clustering as a means of grouping like items\n",
    "\n",
    "Smaller K values result in larger cluster sizes which statistically results in larger entropies (ie. greater diversity within clusters). This is especially true for trying to fit data containing 10 unique labels into clusters of $K=5$; there are more labels than clusters so the maximum accuracy would only be 50% in this case\n",
    "\n",
    "However, intuitively $K=10$ should score the highest because there are 10 unique values in the dataset (representing numbers 0-9) but the algorithm converged to a local optima "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
